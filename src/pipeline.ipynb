{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамбль моделей. Классификация меланоцитных заболеваний и классификация из меланоцитных меланом и невусов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from dvclive import Live\n",
    "import csv\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция изменения размера изображений в соответствии со входным размером модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_normalize(image_path, output_path, size=(224, 224), format='JPEG'):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(size)\n",
    "    if image.mode in ['RGBA', 'P']:\n",
    "        image = image.convert('RGB')\n",
    "    image.save(output_path, format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(input_dir, output_dir, csv_path, test_size=0.2):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create directories for each label\n",
    "    for label in data['diagnosis'].unique():\n",
    "        if label == 'MEL':\n",
    "            os.makedirs(os.path.join(output_dir, 'train', label,\"MEL\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'train', label,\"NV\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'test', label,\"NV\"), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'test', label,\"MEL\"), exist_ok=True)\n",
    "        else:\n",
    "            os.makedirs(os.path.join(output_dir, 'train', label), exist_ok=True)\n",
    "            os.makedirs(os.path.join(output_dir, 'test', label), exist_ok=True)\n",
    "\n",
    "\n",
    "    # Split data into training and testing\n",
    "    train_df, test_df = train_test_split(data, test_size=test_size,random_state=22)\n",
    "\n",
    "\n",
    "    # Process train images with a progress bar\n",
    "    for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc='Processing train images'):\n",
    "        image_path = os.path.join(input_dir, row['image_name'] + '.jpg')\n",
    "        if str(row['melanocit']) != 'nan':\n",
    "            if os.path.exists(image_path):\n",
    "                output_path = os.path.join(output_dir, 'train', row['diagnosis'], str(row['melanocit']), row['image_name'] + '.jpg')\n",
    "                resize_and_normalize(image_path, output_path)\n",
    "        else:\n",
    "            if os.path.exists(image_path):\n",
    "                output_path = os.path.join(output_dir, 'train', row['diagnosis'], row['image_name'] + '.jpg')\n",
    "                resize_and_normalize(image_path, output_path)\n",
    "\n",
    "    # Process test images with a progress bar\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc='Processing test images'):\n",
    "        image_path = os.path.join(input_dir, row['image_name'] + '.jpg')\n",
    "        if str(row['melanocit']) != 'nan':\n",
    "            if os.path.exists(image_path):\n",
    "                output_path = os.path.join(output_dir, 'test', row['diagnosis'], str(row['melanocit']), row['image_name'] + '.jpg')\n",
    "                resize_and_normalize(image_path, output_path)\n",
    "        else:\n",
    "            if os.path.exists(image_path):\n",
    "                output_path = os.path.join(output_dir, 'test', row['diagnosis'], row['image_name'] + '.jpg')\n",
    "                resize_and_normalize(image_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train images: 100%|██████████| 20264/20264 [02:46<00:00, 121.72it/s]\n",
      "Processing test images: 100%|██████████| 5067/5067 [00:43<00:00, 115.55it/s]\n",
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tsrc/pipeline.ipynb\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/home/jovyan/ensemble-of-models/data/raw/classification/isic2019_train\"\n",
    "output_dir = \"/home/jovyan/ensemble-of-models/data/preprocessed\"\n",
    "csv_path = \"/home/jovyan/ensemble-of-models/data/raw/classification/ans_isic.csv\"\n",
    "preprocess_dataset(input_dir, output_dir, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 11:22:51.363700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730719371.376981 3608098 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730719371.380986 3608098 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 11:22:51.397210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer, DefaultDataCollator\n",
    "from transformers import ViTImageProcessor, ViTConfig\n",
    "from datasets import Dataset, load_metric\n",
    "from dvclive import Live\n",
    "from transformers.integrations import DVCLiveCallback\n",
    "import tqdm\n",
    "import torch\n",
    "from datasets import DatasetDict\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    GaussianBlur,\n",
    "    ToTensor,\n",
    "    RandomRotation,\n",
    ")\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from PIL import Image\n",
    "import glob\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс тренировки моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, label_map, model, output_path, epoch, batch_size, data_path):\n",
    "        self.LABEL_MAP = label_map\n",
    "        self.model = model\n",
    "        self.output_path = output_path\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def train_model(self):\n",
    "        def cust_load_model(data_dir): #кастомный способ загрузки датасета \n",
    "            dataset = DatasetDict()\n",
    "            \n",
    "            for train_test in os.listdir(data_dir):\n",
    "                train_test_path = os.path.join(data_dir, train_test)\n",
    "                \n",
    "                if not os.path.isdir(train_test_path):\n",
    "                    continue \n",
    "                \n",
    "                image_paths = [] \n",
    "                class_labels = [] \n",
    "                subclass_labels = [] \n",
    "                \n",
    "                for class_dir in os.listdir(train_test_path):\n",
    "                    class_path = os.path.join(train_test_path, class_dir) \n",
    "                    \n",
    "                    if not os.path.isdir(class_path):\n",
    "                        continue \n",
    "                    \n",
    "                    if class_dir == 'MEL':\n",
    "                        for subclass_dir in os.listdir(class_path): \n",
    "                            subclass_path = os.path.join(class_path, subclass_dir) \n",
    "                            if os.path.isdir(subclass_path): \n",
    "                                for image_file in glob.glob(os.path.join(subclass_path, '*.jpg')):\n",
    "                                    image_paths.append(Image.open(image_file))  \n",
    "                                    class_labels.append(class_dir)\n",
    "                                    subclass_labels.append(subclass_dir) \n",
    "                    else:\n",
    "                        for image_file in glob.glob(os.path.join(class_path, '*.jpg')):\n",
    "                            image_paths.append(Image.open(image_file))  \n",
    "                            class_labels.append(class_dir)\n",
    "                            subclass_labels.append(class_dir) \n",
    "\n",
    "                dat = Dataset.from_dict({\n",
    "                    'image': image_paths,\n",
    "                    'class_label': class_labels,\n",
    "                    'subclass_label': subclass_labels\n",
    "                })\n",
    "                dataset[train_test] = dat \n",
    "\n",
    "            return dataset\n",
    "\n",
    "        def melanocit_preprocess(example): #обработка для классификатора меланоцитов\n",
    "            return{\n",
    "                'image' : example['image'],\n",
    "                'label' : example['class_label']\n",
    "            }\n",
    "        def melanoma_preprocess(example): #обработка для классификатора меланом и невусов\n",
    "            return{\n",
    "                'image' : example['image'],\n",
    "                'label' : example['subclass_label']\n",
    "            }\n",
    "        train_dataset = cust_load_model(self.data_path)\n",
    "        if list(self.LABEL_MAP.keys()) == ['MEL','NOTMEL']:\n",
    "            train_dataset['train'] = train_dataset['train'].map(melanocit_preprocess)\n",
    "            train_dataset['test'] = train_dataset['test'].map(melanocit_preprocess)\n",
    "            train_dataset = train_dataset.class_encode_column(\"label\")\n",
    "        else:\n",
    "            train_dataset['train'] = train_dataset['train'].map(melanoma_preprocess)\n",
    "            train_dataset['test'] = train_dataset['test'].map(melanoma_preprocess)\n",
    "            train_dataset = train_dataset.class_encode_column(\"label\")\n",
    "\n",
    "        image_processor  = AutoImageProcessor.from_pretrained(self.model)\n",
    "\n",
    "        normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "        if \"height\" in image_processor.size:\n",
    "            size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "            crop_size = size\n",
    "            max_size = None\n",
    "        elif \"shortest_edge\" in image_processor.size:\n",
    "            size = image_processor.size[\"shortest_edge\"]\n",
    "            crop_size = (size, size)\n",
    "            max_size = image_processor.size.get(\"longest_edge\")\n",
    "        train_transforms = Compose(\n",
    "                [\n",
    "                    Resize(size),\n",
    "                    ToTensor(),\n",
    "                    normalize,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "                [\n",
    "                    Resize(size),\n",
    "                    ToTensor(),\n",
    "                    normalize,\n",
    "                ]\n",
    "            )\n",
    "        def preprocess_train(example_batch):\n",
    "            \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "            example_batch[\"pixel_values\"] = [\n",
    "                train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "            ]\n",
    "            return example_batch\n",
    "\n",
    "        def preprocess_val(example_batch):\n",
    "            \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "            example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "            return example_batch\n",
    "\n",
    "        train_dataset['train'].set_transform(preprocess_val)\n",
    "        train_dataset['test'].set_transform(preprocess_val)\n",
    "\n",
    "        acc_metric = evaluate.load(\"accuracy\", trust_remote_code=True)\n",
    "        f1_metric = evaluate.load(\"f1\", trust_remote_code=True)\n",
    "\n",
    "        def collate_fn(examples):\n",
    "            pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "            labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "            return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            accuracy = acc_metric.compute(predictions=predictions, references=labels)\n",
    "            f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "            return {\"accuracy\": accuracy['accuracy'], \"f1\": f1['f1']}\n",
    "\n",
    "        labels = train_dataset['train'].features[\"label\"].names\n",
    "        label2id, id2label = dict(), dict()\n",
    "        for i, label in enumerate(labels):\n",
    "            label2id[label] = i\n",
    "            id2label[i] = label\n",
    "\n",
    "\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "        self.model, \n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    "        )\n",
    "\n",
    "        args = TrainingArguments(\n",
    "        self.output_path,\n",
    "        remove_unused_columns=False,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        gradient_accumulation_steps=4,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        push_to_hub=False,\n",
    "        per_device_train_batch_size=self.batch_size,\n",
    "        num_train_epochs=self.epoch,\n",
    "        )   \n",
    "        trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset['train'],\n",
    "        eval_dataset=train_dataset['test'],\n",
    "        tokenizer=image_processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=collate_fn,\n",
    "        )\n",
    "        trainer.train()\n",
    "        trainer.save_model(self.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(output_path,data_path,params_file):\n",
    "    path_model_1 = output_path + '/model_mel_notmel.pkl'\n",
    "    path_model_2 = output_path + '/model_mel_nv.pkl'\n",
    "    with open(params_file, 'r') as f:\n",
    "        params = yaml.safe_load(f)\n",
    "\n",
    "    TrainModel(params['model_mel_notmel'][\"label_map\"],params['model_mel_notmel'][\"arch\"], path_model_1,params['model_mel_notmel']['train'][\"epochs\"], params['model_mel_notmel']['train'][\"batch_size\"],data_path).train_model()\n",
    "    TrainModel(params['model_mel_nv'][\"label_map\"],params['model_mel_nv'][\"arch\"], path_model_2, params['model_mel_nv']['train'][\"epochs\"], params['model_mel_nv']['train'][\"batch_size\"],data_path).train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 19547/19547 [00:07<00:00, 2615.95 examples/s]\n",
      "Map: 100%|██████████| 4903/4903 [00:01<00:00, 2817.38 examples/s]\n",
      "Casting to class labels: 100%|██████████| 4903/4903 [00:00<00:00, 582024.52 examples/s]\n",
      "Casting to class labels: 100%|██████████| 19547/19547 [00:00<00:00, 720629.87 examples/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window16-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [305/305 17:24, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.270321</td>\n",
       "      <td>0.885376</td>\n",
       "      <td>0.857804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tsrc/pipeline.ipynb\n",
      "Map: 100%|██████████| 19547/19547 [00:06<00:00, 2816.07 examples/s]\n",
      "Map: 100%|██████████| 4903/4903 [00:01<00:00, 2608.96 examples/s]\n",
      "Casting to class labels: 100%|██████████| 4903/4903 [00:00<00:00, 589194.98 examples/s]\n",
      "Casting to class labels: 100%|██████████| 19547/19547 [00:00<00:00, 719788.42 examples/s]\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [305/305 11:40, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.452547</td>\n",
       "      <td>0.824801</td>\n",
       "      <td>0.781603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\tsrc/pipeline.ipynb\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/home/jovyan/ensemble-of-models/models\"\n",
    "data_path = \"/home/jovyan/ensemble-of-models/data/preprocessed\"\n",
    "params_file = \"/home/jovyan/ensemble-of-models/params.yaml\"\n",
    "start_train(output_path, data_path, params_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-07 13:27:31.265715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730986051.278360 3818452 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730986051.282009 3818452 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 13:27:31.296958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import yaml, json\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification, ViTFeatureExtractor, pipeline, ViTImageProcessor\n",
    "import datasets\n",
    "from datasets import load_metric, load_dataset\n",
    "import dvclive\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from markdownwriter import MarkdownWriter\n",
    "import pandas as pd\n",
    "from markdownwriter import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def save_classification_report(live, references, predictions, labels):\n",
    "    # Generate the classification report as a dictionary\n",
    "    report = classification_report(references, predictions, target_names=labels, output_dict=True)\n",
    "    \n",
    "    # Specify the path for the JSON file\n",
    "    report_path = \"classification_report.json\"\n",
    "    \n",
    "    # Serialize the report dictionary to a JSON formatted string and save it to a file\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(report, f, indent=4)  # `indent=4` for pretty-printing\n",
    "    \n",
    "    # Log the JSON file as an artifact with DVCLive\n",
    "    live.log_artifact(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix(live, references, predictions, labels):\n",
    "    cm = confusion_matrix(references, predictions, labels=list(LABEL_MAP.values()))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "    live.log_artifact(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кастомный способ загрузки датасета для предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_load_model(data_dir): #кастомный способ загрузки датасета \n",
    "    dataset = DatasetDict()\n",
    "\n",
    "    for train_test in os.listdir(data_dir):\n",
    "        train_test_path = os.path.join(data_dir, train_test)\n",
    "        \n",
    "        if not os.path.isdir(train_test_path):\n",
    "            continue\n",
    "        \n",
    "        image_paths = [] \n",
    "        class_labels = [] \n",
    "        subclass_labels = [] \n",
    "        \n",
    "        for class_dir in os.listdir(train_test_path):\n",
    "            class_path = os.path.join(train_test_path, class_dir) \n",
    "            \n",
    "            if not os.path.isdir(class_path):\n",
    "                continue \n",
    "            \n",
    "            if class_dir == 'MEL':\n",
    "                for subclass_dir in os.listdir(class_path): \n",
    "                    subclass_path = os.path.join(class_path, subclass_dir) \n",
    "                    \n",
    "                    if os.path.isdir(subclass_path): \n",
    "                        for image_file in glob.glob(os.path.join(subclass_path, '*.jpg')):\n",
    "                            image_paths.append(Image.open(image_file))\n",
    "                            class_labels.append(class_dir)\n",
    "                            subclass_labels.append(subclass_dir) \n",
    "            else:\n",
    "                for image_file in glob.glob(os.path.join(class_path, '*.jpg')):\n",
    "                    image_paths.append(Image.open(image_file))\n",
    "                    class_labels.append(class_dir)\n",
    "                    subclass_labels.append(class_dir) \n",
    "\n",
    "        dat = Dataset.from_dict({\n",
    "            'image': image_paths,\n",
    "            'class_label': class_labels,\n",
    "            'subclass_label': subclass_labels\n",
    "        })\n",
    "        dataset[train_test] = dat\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_path, model_path, params_file):\n",
    "    # Load parameters and model\n",
    "    with open(params_file, 'r') as f:\n",
    "        params = yaml.safe_load(f)\n",
    "        \n",
    "    \n",
    "    model1 = load_model(model_path+'model_mel_notmel.pkl')\n",
    "    model2 = load_model(model_path+'model_mel_nv.pkl')\n",
    "    feature_extractor1 = ViTImageProcessor.from_pretrained(model_path+'model_mel_notmel.pkl')\n",
    "    feature_extractor2 = ViTImageProcessor.from_pretrained(model_path+'model_mel_nv.pkl')\n",
    "\n",
    "    # Prepare data and evaluation pipeline\n",
    "    full_dataset = cust_load_model(data_path)\n",
    "    test_dataset = full_dataset[\"test\"]\n",
    "    \n",
    "    eval_pipeline1 = pipeline(\"image-classification\", model=model1, feature_extractor=feature_extractor1)\n",
    "    eval_pipeline2 = pipeline(\"image-classification\", model=model2, feature_extractor=feature_extractor2)\n",
    "\n",
    "    # Collect predictions and references with a progress bar\n",
    "    predictions1 = []\n",
    "    references1 = []\n",
    "    predictions2 = []\n",
    "    references2 = []\n",
    "    label_map_1 = params['model_mel_notmel'][\"label_map\"]\n",
    "    label_map_2 = params['model_mel_nv'][\"label_map\"]\n",
    "\n",
    "    for example in tqdm(test_dataset, desc=\"Processing Images\", leave=True):\n",
    "        result1 = eval_pipeline1(example[\"image\"])\n",
    "        prediction_label1 = result1[0]['label'].split('_')[-1]\n",
    "        prediction1 = label_map_1.get(prediction_label1,prediction_label1)\n",
    "        reference1 = label_map_1.get(example['class_label'],example['class_label'])\n",
    "        predictions1.append(prediction1)\n",
    "        references1.append(reference1)\n",
    "        if prediction_label1=='MEL':\n",
    "            result2 = eval_pipeline2(example['image'])\n",
    "            prediction_label2 = result2[0]['label'].split('_')[-1]\n",
    "            prediction2 = label_map_2.get(prediction_label2,prediction_label2)\n",
    "            reference2 = label_map_2.get(example['subclass_label'],example['subclass_label'])\n",
    "            predictions2.append(prediction2)\n",
    "            references2.append(reference2)\n",
    "\n",
    "\n",
    "    f1_m1 = f1_score(references1, predictions1, average='macro')  # You can change average to 'micro', 'weighted', or None\n",
    "    precision_m1 = precision_score(references1, predictions1, average='macro')\n",
    "    accuracy_m1 = accuracy_score(references1, predictions1)\n",
    "\n",
    "    f1_m2 = f1_score(references2, predictions2, average='macro')  # You can change average to 'micro', 'weighted', or None\n",
    "    precision_m2 = precision_score(references2, predictions2, average='macro')\n",
    "    accuracy_m2 = accuracy_score(references2, predictions2)\n",
    "\n",
    "    print(f\"F1_model_1 Score (Macro): {f1_m1}\")\n",
    "    print(f\"F1_model_2 Score (Macro): {f1_m2}\")\n",
    "    print(f\"accuracy_model_1 (Macro): {accuracy_m1}\")\n",
    "    print(f\"accuracy_model_2 (Macro): {accuracy_m2}\")\n",
    "\n",
    "    # Classification report and confusion matrix model1\n",
    "    cr1 = classification_report(references1, predictions1, target_names=list(label_map_1.keys()), zero_division=0, output_dict=True)\n",
    "    cm1 = confusion_matrix(references1, predictions1, labels=list(label_map_1.values()))\n",
    "    \n",
    "    # Classification report and confusion matrix model2\n",
    "    cr2 = classification_report(references2, predictions2, target_names=list(label_map_2.keys()), zero_division=0, output_dict=True)\n",
    "    cm2 = confusion_matrix(references2, predictions2, labels=list(label_map_2.values()))\n",
    "    \n",
    "    # Convert classification report and confusion matrix to DataFrame for better formatting\n",
    "    report_df1 = pd.DataFrame(cr1).transpose()\n",
    "    matrix_df1 = pd.DataFrame(cm1)\n",
    "\n",
    "    report_df2 = pd.DataFrame(cr2).transpose()\n",
    "    matrix_df2 = pd.DataFrame(cm2)\n",
    "\n",
    "    print(\"Report DataFrame 1:\")\n",
    "    print(report_df1)\n",
    "    print(\"\\nMatrix DataFrame 1:\")\n",
    "    print(matrix_df1)\n",
    "    print(\"\\nReport DataFrame 2:\")\n",
    "    print(report_df2)\n",
    "    print(\"\\nMatrix DataFrame 2:\")\n",
    "    print(matrix_df2)\n",
    "    cm1 = confusion_matrix(references1, predictions1)\n",
    "    cm2 = confusion_matrix(references2, predictions2)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(label_map_1.values()),\n",
    "                yticklabels=list(label_map_1.values()))\n",
    "    plt.title('Confusion Matrix Model 1')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(label_map_2.values()),\n",
    "                yticklabels=list(label_map_2.values()))\n",
    "    plt.title('Confusion Matrix Model 2')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 5/4903 [00:15<4:00:30,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 6/4903 [00:19<4:21:52,  3.21s/it]"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jovyan/ensemble-of-models/data/preprocessed\"\n",
    "model_path = \"/home/jovyan/ensemble-of-models/models/\"\n",
    "params_file = \"/home/jovyan/ensemble-of-models/params.yaml\"\n",
    "evaluate_model(data_path, model_path, params_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_writer = MarkdownWriter(f\"report/report_ans.md\")\n",
    "#md_writer.header1('Report')\n",
    "\n",
    "md_writer.header2('Params')\n",
    "\n",
    "md_writer.print_config(params)\n",
    "\n",
    "train_description = describe_dataset('data/preprocessed/train/')\n",
    "test_description = describe_dataset('data/preprocessed/test/')\n",
    "md_writer.describe_dataset_markdown(train_description, \"Training Dataset Description\")\n",
    "md_writer.describe_dataset_markdown(test_description, \"Testing Dataset Description\")\n",
    "\n",
    "md_writer.header2('Metrics')\n",
    "md_writer.print_data(f\"F1 Score (Macro) Model1: **{f1_m1}**\\n\")\n",
    "md_writer.print_data(f\"Accuracy Model1: **{cr1['accuracy']}**\\n\")\n",
    "\n",
    "md_writer.print_data(f\"F1 Score (Macro) Model2: **{f1_m2}**\\n\")\n",
    "md_writer.print_data(f\"Accuracy Model2: **{cr2['accuracy']}**\\n\")\n",
    "\n",
    "md_writer.header2('Classification Report')\n",
    "\n",
    "md_writer.print_data(report_df1.to_markdown(index=True) + '\\n\\n')\n",
    "md_writer.print_data(report_df2.to_markdown(index=True) + '\\n\\n')\n",
    "\n",
    "md_writer.header2('Confusion Matrix')\n",
    "matrix_df1.index = [key for key, value in sorted(label_map_1.items(), key=lambda item: item[1])]\n",
    "matrix_df1.columns = [key for key, value in sorted(label_map_1.items(), key=lambda item: item[1])]\n",
    "md_writer.print_data(matrix_df1.to_markdown(index=True) + '\\n')\n",
    "\n",
    "md_writer.header2('Confusion Matrix Model 2')\n",
    "matrix_df2.index = [key for key, value in sorted(label_map_2.items(), key=lambda item: item[1])]\n",
    "matrix_df2.columns = [key for key, value in sorted(label_map_2.items(), key=lambda item: item[1])]\n",
    "md_writer.print_data(matrix_df1.to_markdown(index=True) + '\\n')\n",
    "\n",
    "# Define the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', xticklabels=list(label_map_1.keys()), yticklabels=list(label_map_1.keys()))\n",
    "plt.title('Confusion Matrix Model 1')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Save the plot model1 as an image file\n",
    "plt.savefig('report/confusion_matrix_m1.png', bbox_inches='tight')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues', xticklabels=list(label_map_2.keys()), yticklabels=list(label_map_2.keys()))\n",
    "plt.title('Confusion Matrix Model 2')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Save the plot model2 as an image file\n",
    "plt.savefig('report/confusion_matrix_m2.png', bbox_inches='tight')\n",
    "\n",
    "md_writer.add_image('report/confusion_matrix_m1.png', 'Confusion matrix')\n",
    "md_writer.add_image('report/confusion_matrix_m2.png', 'Confusion matrix')\n",
    "# md_writer.add_image('dvctrain/static/eval/accuracy.png', 'Accuracy during the training')\n",
    "# md_writer.add_image('dvctrain/static/eval/f1.png', 'F1Score during the training')\n",
    "# md_writer.add_image('dvctrain/static/eval/loss.png', 'Loss during the training')\n",
    "md_writer.write_toc('Report '+ params['model_mel_notmel']['arch']+\" \"+ params['model_mel_nv']['arch'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
